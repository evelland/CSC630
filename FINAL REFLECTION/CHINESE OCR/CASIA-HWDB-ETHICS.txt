CASIA-HWDB

USER EXPERIENCE AND ETHICAL ANALYSIS

In comparison with many of the subsets of machine learning, Optical Character Recognition has little impact onto the wellbeing of its users. It does not determine ones societal worth, diagnose life-threatening disease, or threaten labor work. Still, there are a few key areas where its impact can be negative -> depending on the accuracy, training, and application of the model and its decisions.
To describe the potential use cases and harm that could be caused as a result of them, I will outline my main idea for the application of my model.
--------------------------------------------------------------------------------
I would like to use OCR to develop a language learning application. The app (built in SwiftUI) would integrate with TensorFLow using CoreML. The app would allow users to practice Chinese by drawing characters, at which point the app abstracts the drawing into a bitmap and returns the most likely character that has been drawn
--------------------------------------------------------------------------------
Communication is essential, and any application that influences ones ability to communicate can have negative effects. If the model has too low an accuracy, then it has the potential to mislead its users and incorrectly identify characters. If the knowledge that the user gained from the application were to be used in a serious setting, such as a court case, it could cause life changing error. It is nearly impossible to create a classification algorithm with 100% accuracy. The bulk of the ethical dilemma occurs in consideration of the line that must be drawn between accuracy and inaccuracy. With a large enough pool of users, detrimental error is inevitable. Is 98% accuracy sufficient? 99%? 99.5%? The most ethical route of action would likely be to tell the user that the model's results should not be trusted; however, at that point, there isn't really a point in using the model at all. As an auxiliary point, the issue could be diminished by making the model return a prediction of the most likely values, as opposed to a single character - increasing its chance of guessing the correct value (provided that the model has a low enough loss, of course)

Additionally, there is the issue of representation within the training data. Chinese is heavily influenced by dialect, and as such, there are variations in characters across regions. CASIA-HWDB, the set used for this analysis, was compiled by 320 - 420 writers (depending on the percentage of data accessed) from Beijing. The data does not fully encompass the specific styles and patterns of more rural regions.